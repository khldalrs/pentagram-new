{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAaJRjqJtkiq",
        "outputId": "d34c86f0-3bee-42a9-fe48-943f406ac2ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: modal-client in /usr/local/lib/python3.10/dist-packages (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade modal-client\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set Modal Token ID and Secret as environment variables\n",
        "os.environ[\"MODAL_TOKEN_ID\"] = #Token ID here\n",
        "os.environ[\"MODAL_TOKEN_SECRET\"] = #Token secret here\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zNEGVM1etqbB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install modal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IVu7psrMXwh",
        "outputId": "c2da7e0d-2589-426f-8cbf-4ba77e5a1d90"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: modal in /usr/local/lib/python3.10/dist-packages (0.68.52)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from modal) (3.11.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from modal) (2024.12.14)\n",
            "Requirement already satisfied: click>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from modal) (8.1.7)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from modal) (0.115.6)\n",
            "Requirement already satisfied: grpclib==0.4.7 in /usr/local/lib/python3.10/dist-packages (from modal) (0.4.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<6.0,>=3.19 in /usr/local/lib/python3.10/dist-packages (from modal) (4.25.5)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from modal) (13.9.4)\n",
            "Requirement already satisfied: synchronicity~=0.9.8 in /usr/local/lib/python3.10/dist-packages (from modal) (0.9.8)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from modal) (0.10.2)\n",
            "Requirement already satisfied: typer>=0.9 in /usr/local/lib/python3.10/dist-packages (from modal) (0.15.1)\n",
            "Requirement already satisfied: types-certifi in /usr/local/lib/python3.10/dist-packages (from modal) (2021.10.8.3)\n",
            "Requirement already satisfied: types-toml in /usr/local/lib/python3.10/dist-packages (from modal) (0.10.8.20240310)\n",
            "Requirement already satisfied: watchfiles in /usr/local/lib/python3.10/dist-packages (from modal) (1.0.3)\n",
            "Requirement already satisfied: typing-extensions~=4.6 in /usr/local/lib/python3.10/dist-packages (from modal) (4.12.2)\n",
            "Requirement already satisfied: h2<5,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from grpclib==0.4.7->modal) (4.1.0)\n",
            "Requirement already satisfied: multidict in /usr/local/lib/python3.10/dist-packages (from grpclib==0.4.7->modal) (6.1.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->modal) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->modal) (2.18.0)\n",
            "Requirement already satisfied: sigtools>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from synchronicity~=0.9.8->modal) (4.0.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9->modal) (1.5.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->modal) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->modal) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->modal) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->modal) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->modal) (1.5.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->modal) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->modal) (1.18.3)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->modal) (0.41.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi->modal) (2.10.3)\n",
            "Requirement already satisfied: anyio>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from watchfiles->modal) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.0.0->watchfiles->modal) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.0.0->watchfiles->modal) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio>=3.0.0->watchfiles->modal) (1.2.2)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3.1.0->grpclib==0.4.7->modal) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3.1.0->grpclib==0.4.7->modal) (4.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->modal) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->modal) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->modal) (2.27.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import modal\n",
        "from PIL import Image\n",
        "\n",
        "# Create the image with all required dependencies\n",
        "image = modal.Image.debian_slim().pip_install(\n",
        "    \"diffusers\",\n",
        "    \"transformers\",\n",
        "    \"accelerate\",\n",
        "    \"torch\",\n",
        "    \"fastapi\",\n",
        "    \"pillow\"\n",
        ")\n",
        "\n",
        "# Define stub (app) after image definition\n",
        "app = modal.Stub(\n",
        "    \"sdxl-turbo-with-caption\",\n",
        "    image=image\n",
        ")\n",
        "\n",
        "@app.cls(gpu=\"A100\")\n",
        "class Model:\n",
        "    def __init__(self):\n",
        "        self.pipe = None\n",
        "        self.caption_model = None\n",
        "        self.caption_processor = None\n",
        "\n",
        "    @modal.enter()\n",
        "    def load_weights(self):\n",
        "        from diffusers import AutoPipelineForText2Image\n",
        "        from transformers import BlipForConditionalGeneration, BlipProcessor\n",
        "        import torch\n",
        "\n",
        "        # Load SDXL Turbo\n",
        "        self.pipe = AutoPipelineForText2Image.from_pretrained(\n",
        "            \"stabilityai/sdxl-turbo\",\n",
        "            torch_dtype=torch.float16,\n",
        "            variant=\"fp16\"\n",
        "        )\n",
        "        self.pipe.to(\"cuda\")\n",
        "\n",
        "        # Load BLIP captioning model\n",
        "        self.caption_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "        self.caption_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\").to(\"cuda\")\n",
        "\n",
        "    def generate_caption(self, image):\n",
        "        inputs = self.caption_processor(images=image, return_tensors=\"pt\").to(\"cuda\")\n",
        "        generated_ids = self.caption_model.generate(**inputs, max_new_tokens=50)\n",
        "        caption = self.caption_processor.decode(generated_ids[0], skip_special_tokens=True)\n",
        "        return caption\n",
        "\n",
        "    @modal.web_endpoint(method=\"GET\")\n",
        "    def generate(self, prompt: str = \"A cinematic shot of a baby racoon wearing an intricate italian priest robe.\"):\n",
        "        import io\n",
        "        from fastapi import Response\n",
        "        import json\n",
        "\n",
        "        print(f\"Generating image for prompt: {prompt}\")\n",
        "\n",
        "        # Generate image\n",
        "        image = self.pipe(\n",
        "            prompt=prompt,\n",
        "            num_inference_steps=1,\n",
        "            guidance_scale=0.0\n",
        "        ).images[0]\n",
        "\n",
        "        # Generate caption\n",
        "        caption = self.generate_caption(image)\n",
        "        print(f\"Generated caption: {caption}\")\n",
        "\n",
        "        # Convert image to bytes\n",
        "        buffer = io.BytesIO()\n",
        "        image.save(buffer, format=\"JPEG\")\n",
        "        buffer.seek(0)\n",
        "        image_bytes = buffer.getvalue()\n",
        "\n",
        "        # Create response with both image and caption\n",
        "        response = Response(\n",
        "            content=json.dumps({\n",
        "                \"image_bytes\": image_bytes.hex(),\n",
        "                \"caption\": caption\n",
        "            }),\n",
        "            media_type=\"application/json\"\n",
        "        )\n",
        "        response.headers[\"Access-Control-Allow-Origin\"] = \"*\"\n",
        "        return response\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E1dVLUX8NE-",
        "outputId": "10dcb58b-77cc-4268-cc47-a91711f955b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Optimized ###################\n",
        "%%writefile app.py\n",
        "\n",
        "import modal\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# Define the models to be downloaded during image creation\n",
        "SDXL_MODEL_ID = \"stabilityai/sdxl-turbo\"\n",
        "BLIP_MODEL_ID = \"Salesforce/blip-image-captioning-large\"\n",
        "\n",
        "def download_models():\n",
        "    from diffusers import AutoPipelineForText2Image\n",
        "    from transformers import BlipForConditionalGeneration, BlipProcessor\n",
        "\n",
        "    # Download models during image building\n",
        "    AutoPipelineForText2Image.from_pretrained(\n",
        "        SDXL_MODEL_ID,\n",
        "        torch_dtype=torch.float16,\n",
        "        variant=\"fp16\"\n",
        "    )\n",
        "    BlipProcessor.from_pretrained(BLIP_MODEL_ID)\n",
        "    BlipForConditionalGeneration.from_pretrained(BLIP_MODEL_ID)\n",
        "\n",
        "# Create the image with optimized dependencies\n",
        "image = (\n",
        "    modal.Image.debian_slim(python_version=\"3.10\")\n",
        "    .pip_install(\n",
        "        \"diffusers>=0.24.0\",\n",
        "        \"transformers>=4.36.0\",\n",
        "        \"accelerate>=0.26.0\",\n",
        "        \"torch>=2.1.0\",\n",
        "        \"fastapi>=0.109.0\",\n",
        "        \"pillow>=10.0.0\",\n",
        "        \"safetensors>=0.4.0\",\n",
        "    )\n",
        "    .pip_install(\"xformers\", pre=True)\n",
        "    .run_function(download_models)\n",
        ")\n",
        "\n",
        "# Create volume for persistent cache\n",
        "volume = modal.Volume.from_name(\"model-cache-vol\", create_if_missing=True)\n",
        "CACHE_PATH = \"/cache\"\n",
        "\n",
        "# Changed from stub to app\n",
        "app = modal.Stub(\"sdxl-turbo-with-caption\", image=image)\n",
        "\n",
        "@app.cls(\n",
        "    gpu=\"A100\",\n",
        "    container_idle_timeout=300,\n",
        "    allow_concurrent_inputs=2,\n",
        "    volumes={CACHE_PATH: volume}\n",
        ")\n",
        "class Model:\n",
        "    def __init__(self):\n",
        "        self.pipe = None\n",
        "        self.caption_model = None\n",
        "        self.caption_processor = None\n",
        "\n",
        "    @modal.enter()\n",
        "    def load_weights(self):\n",
        "        import os\n",
        "        from diffusers import AutoPipelineForText2Image\n",
        "        from transformers import BlipForConditionalGeneration, BlipProcessor\n",
        "        import torch\n",
        "\n",
        "        # Set cache directory\n",
        "        os.environ['TRANSFORMERS_CACHE'] = f\"{CACHE_PATH}/transformers\"\n",
        "        os.environ['DIFFUSERS_CACHE'] = f\"{CACHE_PATH}/diffusers\"\n",
        "\n",
        "        # Enable optimization flags\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "        torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "        # Load SDXL Turbo with optimizations\n",
        "        self.pipe = AutoPipelineForText2Image.from_pretrained(\n",
        "            SDXL_MODEL_ID,\n",
        "            torch_dtype=torch.float16,\n",
        "            variant=\"fp16\",\n",
        "            use_safetensors=True,\n",
        "            cache_dir=f\"{CACHE_PATH}/diffusers\"\n",
        "        )\n",
        "        self.pipe.enable_xformers_memory_efficient_attention()\n",
        "        self.pipe.to(\"cuda\")\n",
        "\n",
        "        # Load BLIP with optimizations\n",
        "        self.caption_processor = BlipProcessor.from_pretrained(\n",
        "            BLIP_MODEL_ID,\n",
        "            cache_dir=f\"{CACHE_PATH}/transformers\"\n",
        "        )\n",
        "        self.caption_model = BlipForConditionalGeneration.from_pretrained(\n",
        "            BLIP_MODEL_ID,\n",
        "            torch_dtype=torch.float16,\n",
        "            cache_dir=f\"{CACHE_PATH}/transformers\"\n",
        "        ).to(\"cuda\")\n",
        "\n",
        "    def generate_caption(self, image):\n",
        "        with torch.inference_mode():\n",
        "            inputs = self.caption_processor(images=image, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
        "            generated_ids = self.caption_model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=50,\n",
        "                num_beams=1,\n",
        "                length_penalty=1.0\n",
        "            )\n",
        "            caption = self.caption_processor.decode(generated_ids[0], skip_special_tokens=True)\n",
        "        return caption\n",
        "\n",
        "    @modal.web_endpoint(method=\"GET\")\n",
        "    async def generate(self, prompt: str = \"A cinematic shot of a baby racoon wearing an intricate italian priest robe.\"):\n",
        "        import io\n",
        "        from fastapi import Response\n",
        "        import json\n",
        "\n",
        "        try:\n",
        "            with torch.inference_mode():\n",
        "                image = self.pipe(\n",
        "                    prompt=prompt,\n",
        "                    num_inference_steps=1,\n",
        "                    guidance_scale=0.0,\n",
        "                ).images[0]\n",
        "\n",
        "            caption = self.generate_caption(image)\n",
        "\n",
        "            buffer = io.BytesIO()\n",
        "            image.save(buffer, format=\"JPEG\", quality=90, optimize=True)\n",
        "            image_bytes = buffer.getvalue()\n",
        "\n",
        "            response = Response(\n",
        "                content=json.dumps({\n",
        "                    \"image_bytes\": image_bytes.hex(),\n",
        "                    \"caption\": caption,\n",
        "                    \"status\": \"success\"\n",
        "                }),\n",
        "                media_type=\"application/json\"\n",
        "            )\n",
        "            response.headers[\"Access-Control-Allow-Origin\"] = \"*\"\n",
        "            return response\n",
        "\n",
        "        except Exception as e:\n",
        "            return Response(\n",
        "                content=json.dumps({\n",
        "                    \"status\": \"error\",\n",
        "                    \"error\": str(e)\n",
        "                }),\n",
        "                media_type=\"application/json\",\n",
        "                status_code=500\n",
        "            )\n",
        "\n",
        "# Optional: Add keepalive function to prevent cold starts\n",
        "@app.function(schedule=modal.Period(minutes=4))\n",
        "def keepalive():\n",
        "    resp = Model().generate.remote(\"test prompt\")\n",
        "    print(\"Keeping container warm:\", resp)\n",
        "\n",
        "# Optional: Add warmup function\n",
        "@app.function(schedule=modal.Cron(\"30 7 * * *\"))\n",
        "def warmup():\n",
        "    Model().generate.remote(\"warmup prompt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYdNLr4_JiQx",
        "outputId": "9483bee8-cca4-4b38-8a2e-4908afb2d741"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!modal deploy app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7jzG7mWPnj6",
        "outputId": "48f7788b-f20e-4116-8bde-de093ca1da43"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m╭─\u001b[0m\u001b[33m Modal Deprecation Warning (2024-04-29) \u001b[0m\u001b[33m────────────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
            "\u001b[33m│\u001b[0m The use of \"Stub\" has been deprecated in favor of \"App\". This is a pure name change with no      \u001b[33m│\u001b[0m\n",
            "\u001b[33m│\u001b[0m other implications.                                                                              \u001b[33m│\u001b[0m\n",
            "\u001b[33m│\u001b[0m                                                                                                  \u001b[33m│\u001b[0m\n",
            "\u001b[33m│\u001b[0m Source: /content/app.py:44                                                                       \u001b[33m│\u001b[0m\n",
            "\u001b[33m│\u001b[0m   app = modal.Stub(\"sdxl-turbo-with-caption\", image=image)                                       \u001b[33m│\u001b[0m\n",
            "\u001b[33m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[2K\u001b[34m⠸\u001b[0m Creating objects...\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[34m⠦\u001b[0m Creating objects...\n",
            "\u001b[37m├── \u001b[0m🔨 Created mount /content/app.py\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[34m⠏\u001b[0m Creating objects...\n",
            "\u001b[37m├── \u001b[0m🔨 Created mount /content/app.py\n",
            "\u001b[37m├── \u001b[0m🔨 Created function download_models.\n",
            "\u001b[37m├── \u001b[0m🔨 Created function Model.*.\n",
            "\u001b[37m├── \u001b[0m\u001b[34m⠋\u001b[0m Creating function keepalive...\n",
            "\u001b[37m├── \u001b[0m\u001b[34m⠋\u001b[0m Creating function warmup...\n",
            "\u001b[37m└── \u001b[0m🔨 Created web endpoint for Model.generate => \n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[34m⠋\u001b[0m Creating objects...\n",
            "\u001b[37m├── \u001b[0m🔨 Created mount /content/app.py\n",
            "\u001b[37m├── \u001b[0m🔨 Created function download_models.\n",
            "\u001b[37m├── \u001b[0m🔨 Created function Model.*.\n",
            "\u001b[37m├── \u001b[0m🔨 Created function keepalive.\n",
            "\u001b[37m├── \u001b[0m🔨 Created function warmup.\n",
            "\u001b[37m└── \u001b[0m🔨 Created web endpoint for Model.generate => \n",
            "\u001b[37m    \u001b[0m\u001b[4;35mhttps://deuki1209--sdxl-turbo-with-caption-model-generate.modal.run\u001b[0m\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m✓\u001b[0m Created objects.\n",
            "\u001b[37m├── \u001b[0m🔨 Created mount /content/app.py\n",
            "\u001b[37m├── \u001b[0m🔨 Created function download_models.\n",
            "\u001b[37m├── \u001b[0m🔨 Created function Model.*.\n",
            "\u001b[37m├── \u001b[0m🔨 Created function keepalive.\n",
            "\u001b[37m├── \u001b[0m🔨 Created function warmup.\n",
            "\u001b[37m└── \u001b[0m🔨 Created web endpoint for Model.generate => \n",
            "\u001b[37m    \u001b[0m\u001b[4;35mhttps://deuki1209--sdxl-turbo-with-caption-model-generate.modal.run\u001b[0m\n",
            "\u001b[32m✓\u001b[0m App deployed in 1.257s! 🎉\n",
            "\n",
            "View Deployment: \u001b[35mhttps://modal.com/apps/deuki1209/main/deployed/sdxl-turbo-with-caption\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mcWFpt5VR4K5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}